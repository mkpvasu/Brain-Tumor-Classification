{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BT_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMmAR0zbD+fKX414cmX3Jd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkpvasu/Brain-Tumor-Classification/blob/main/BT_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from torchvision.utils import make_grid\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from google.colab import drive "
      ],
      "metadata": {
        "id": "Y72Axe6Wtuz7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E300q8N9tvkT",
        "outputId": "c0142a1a-bb45-4f90-c7c7-1944fcb7bfff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wkr7RXBXt6yL",
        "outputId": "40a1488d-eaff-4888-c274-963b24be0b88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.11.0+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYNC4CO5uTa4",
        "outputId": "a6366887-8691-4f56-befa-3b34c121ebb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 28 20:04:33 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "BcpxiEPnuZP4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BrainTumorDataset(Dataset):\n",
        "  def __init__(self, images, labels):\n",
        "    # Images\n",
        "    self.X = images\n",
        "    # Corresponding Labels\n",
        "    self.y = labels\n",
        "    \n",
        "    # Convert original image numpy array to PIL image and then to a tensor\n",
        "    self.transform = transforms.Compose([transforms.ToPILImage(),\n",
        "        #transforms.Resize((64,64)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Augmenting original image numpy array by resizing it to (64,64) pixels, then rotating it to randomly between [-k,k] degrees and \n",
        "    # then convert it to tensor\n",
        "    self.transform30 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        #transforms.Resize((64,64)),                                         \n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        "\n",
        "    self.transform90 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        #transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(90),\n",
        "        transforms.ToTensor()                                  \n",
        "    ])\n",
        "\n",
        "    self.transform135 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        #transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(135),\n",
        "        transforms.ToTensor()                                  \n",
        "    ])\n",
        "\n",
        "    self.transform180 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        #transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(180),\n",
        "        transforms.ToTensor()                                \n",
        "    ])\n",
        "\n",
        "    self.transform270 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        #transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(270),\n",
        "        transforms.ToTensor()                                \n",
        "    ])\n",
        "\n",
        "    self.transform315 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        #transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(315),\n",
        "        transforms.ToTensor()                                \n",
        "    ])\n",
        "    \n",
        "    self.transform345 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        #transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(345),\n",
        "        transforms.ToTensor()                                \n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    # Returns # of images\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # Transformations for one image of X at a time\n",
        "    # Original image as a tensor\n",
        "    img = self.transform(self.X[idx])\n",
        "\n",
        "    # Transformations are called to augment images and save it to traing the model\n",
        "    img30 = self.transform30(self.X[idx])\n",
        "    img90 = self.transform90(self.X[idx])\n",
        "    img135 = self.transform135(self.X[idx])\n",
        "    img180 = self.transform180(self.X[idx])\n",
        "    img270 = self.transform270(self.X[idx])\n",
        "    img315 = self.transform270(self.X[idx])  \n",
        "    img345 = self.transform270(self.X[idx])    \n",
        "    \n",
        "    # store the transformed images in a list\n",
        "    batch = [img, img30, img90, img135, img180, img270, img315, img345]\n",
        "\n",
        "    # One Hot Encoding\n",
        "    labels = torch.zeros(4, dtype=torch.float32)\n",
        "    labels[int(self.y[idx])] = 1.0\n",
        "\n",
        "    b_labels = [labels, labels, labels, labels, labels, labels, labels, labels]\n",
        "\n",
        "    # 8 augmented images and corresponding labels per sample will be returned\n",
        "    return (torch.stack(b_labels), torch.stack(batch))"
      ],
      "metadata": {
        "id": "iHwCBsE0udk2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pickle.load(open('/content/Drive/My Drive/Colab Notebooks/braintumordata/train_data.pickle', 'rb'))"
      ],
      "metadata": {
        "id": "Bl57l8bZutAe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xt, yt = [], []\n",
        "features, labels = None, None\n",
        "label = []"
      ],
      "metadata": {
        "id": "_QNWqgUfu9cg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for features,labels in train_data:\n",
        "  Xt.append(features)\n",
        "  yt.append(labels)"
      ],
      "metadata": {
        "id": "Z00zv1kXvWnn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The train_data has been divided into training, validation and testing data\n",
        "# 75% - training data\n",
        "# 15% - validation data\n",
        "# 10% - testing data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xt, yt, test_size=0.25, shuffle=True)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.6, shuffle=True)"
      ],
      "metadata": {
        "id": "hFzFwrDjvYiT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clearing memory\n",
        "Xt, yt, labels, label, features, train_data = None, None, None, None, None, None"
      ],
      "metadata": {
        "id": "QP8-QsxAwNsQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BrainTumorDataset(Dataset):\n",
        "  def __init__(self, images, labels):\n",
        "    # images\n",
        "    self.X = images\n",
        "    # labels\n",
        "    self.y = labels\n",
        "    \n",
        "    # Transformation for converting original image array to an image and then convert it to a tensor\n",
        "    self.transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                         transforms.Resize((64,64)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -45 degrees and 45 degrees, and then convert it to a tensor\n",
        "    self.transform1 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((64,64)),                                          \n",
        "        transforms.RandomRotation(45),\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -90 degrees and 90 degrees, and then convert it to a tensor\n",
        "    self.transform2 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(90),\n",
        "        transforms.ToTensor()                                  \n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -120 degrees and 120 degrees, and then convert it to a tensor\n",
        "    self.transform3 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(120),\n",
        "        transforms.ToTensor()                                  \n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -180 degrees and 180 degrees, and then convert it to a tensor\n",
        "    self.transform4 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(180),\n",
        "        transforms.ToTensor()                                \n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -270 degrees and 270 degrees, and then convert it to a tensor\n",
        "    self.transform5 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(270),\n",
        "        transforms.ToTensor()                                \n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -300 degrees and 300 degrees, and then convert it to a tensor\n",
        "    self.transform6 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(300),\n",
        "        transforms.ToTensor()                               \n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -330 degrees and 330 degrees, and then convert it to a tensor\n",
        "    self.transform7 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((64,64)),\n",
        "        transforms.RandomRotation(330),\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    # return length of image samples\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # perform transformations on one instance of X\n",
        "    # Original image as a tensor\n",
        "    data = self.transform(self.X[idx])\n",
        "\n",
        "    # Augmented image at 45 degrees as a tensor\n",
        "    aug45 = self.transform1(self.X[idx])\n",
        "\n",
        "    # Augmented image at 90 degrees as a tensor\n",
        "    aug90 = self.transform2(self.X[idx])\n",
        "\n",
        "    # Augmented image at 120 degrees as a tensor\n",
        "    aug120 = self.transform3(self.X[idx])\n",
        "\n",
        "    # Augmented image at 180 degrees as a tensor\n",
        "    aug180 = self.transform4(self.X[idx])\n",
        "\n",
        "    # Augmented image at 270 degrees as a tensor\n",
        "    aug270 = self.transform5(self.X[idx])\n",
        "\n",
        "    # Augmented image at 300 degrees as a tensor\n",
        "    aug300 = self.transform6(self.X[idx])\n",
        "\n",
        "    # Augmented image at 330 degrees as a tensor\n",
        "    aug330 = self.transform7(self.X[idx])      \n",
        "    \n",
        "    # store the transformed images in a list\n",
        "    new_batch = [data, aug45, aug90, aug120, aug180, aug270, aug300, aug330]\n",
        "\n",
        "    # one-hot encode the labels\n",
        "    labels = torch.zeros(4, dtype=torch.float32)\n",
        "    labels[int(self.y[idx])] = 1.0\n",
        "\n",
        "    new_labels = [labels, labels, labels, labels, labels, labels, labels, labels]\n",
        "\n",
        "    # 8 augmented images and corresponding labels per sample will be returned\n",
        "    return (torch.stack(new_labels), torch.stack(new_batch))"
      ],
      "metadata": {
        "id": "oaky1iDxPbaN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To augmented dataset and save it to corresponding variables\n",
        "\n",
        "train_set = BrainTumorDataset(X_train, y_train)\n",
        "val_set = BrainTumorDataset(X_val, y_val)\n",
        "test_set = BrainTumorDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "8DOTlN3wvcET"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These dataloaders load the dataset to minimize the time device has to wait to retrieve data\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=4, shuffle=True, pin_memory=True, num_workers=8)\n",
        "val_loader = DataLoader(val_set, batch_size=4, shuffle=True, pin_memory=True, num_workers=8)\n",
        "test_loader = DataLoader(test_set, batch_size=10, shuffle=True, pin_memory=True, num_workers=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5WjfDJQvmRT",
        "outputId": "0b78ce7f-43b1-44e3-c336-defb108b138d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device_name)"
      ],
      "metadata": {
        "id": "sZE85sNIvptb"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Resnet50 (50 layers) pretrained model (this model will be pretrined using ImageNet dataset) as our model\n",
        "resnet_50 = models.resnet50(pretrained=True)\n",
        "\n",
        "# Training all parameters\n",
        "for param in resnet_50.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Input for fully connected layer\n",
        "n_inputs = resnet_50.fc.in_features\n",
        "\n",
        "# Creating a new final fully connected layer to make this model perform classification for our dataset (Original pretrined model can classify the \n",
        "# classes it was trained on)\n",
        "resnet_50.fc = nn.Sequential(nn.Linear(n_inputs, 2048),\n",
        "                                nn.SELU(),\n",
        "                                nn.Dropout(p=0.4),\n",
        "                                nn.Linear(2048, 2048),\n",
        "                                nn.SELU(),\n",
        "                                nn.Dropout(p=0.4),\n",
        "                                nn.Linear(2048, 4),\n",
        "                                nn.LogSigmoid())\n",
        "\n",
        "# set all paramters of the model as trainable\n",
        "for name, child in resnet_50.named_children():\n",
        "  for name2, params in child.named_parameters():\n",
        "    params.requires_grad = True\n",
        "\n",
        "# set model to run on GPU or CPU absed on availibility\n",
        "resnet_50.to(device)"
      ],
      "metadata": {
        "id": "eSRzFC3uvsIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy loss is used for classification algorithm here as it is common\n",
        "# GPU is used if available for faster training\n",
        "crossen_loss = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Stochastic Gradient Descent optimizer\n",
        "sgd_opt = torch.optim.SGD(resnet_50.parameters(), momentum=0.9, lr=3e-4)\n",
        "\n",
        "# # of epochs to be trained\n",
        "epochs = 30\n",
        "\n",
        "# Lists to store train, test losses and accuracies\n",
        "train_losses, test_losses, train_accs, test_accs = [],[],[],[]"
      ],
      "metadata": {
        "id": "M_9i5LDrxGEs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(state, is_best, filename='/content/Drive/My Drive/Colab Notebooks/braintumordata/bt_resnet50_bt_intermodel.pth.tar'):\n",
        "    torch.save(state, filename)"
      ],
      "metadata": {
        "id": "Was9MaF6xJ8w"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "wMpaFVD08zp6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set training start time\n",
        "start_time = time.time()\n",
        "\n",
        "# set best_prec loss value as 2 for checkpoint threshold\n",
        "best_loss = 2.5\n",
        "\n",
        "# empty batch variables\n",
        "b = None\n",
        "train_b = None\n",
        "test_b = None\n",
        "\n",
        "# start training\n",
        "for i in range(epochs):\n",
        "    # empty training correct and test correct counter as 0 during every iteration\n",
        "    trn_corr = 0\n",
        "    tst_corr = 0\n",
        "    \n",
        "    # set epoch's starting time\n",
        "    e_start = time.time()\n",
        "    \n",
        "    # train in batches\n",
        "    for b, (y, X) in enumerate(train_loader):\n",
        "        # set label as cuda if device is cuda\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # forward pass image sample\n",
        "        y_pred = resnet_50(X.view(-1, 3, 512, 512))\n",
        "        # calculate loss\n",
        "        loss = crossen_loss(y_pred.float(), torch.argmax(y.view(32, 4), dim=1).long())\n",
        "\n",
        "        # get argmax of predicted tensor, which is our label\n",
        "        predicted = torch.argmax(y_pred, dim=1).data\n",
        "        # if predicted label is correct as true label, calculate the sum for samples\n",
        "        batch_corr = (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n",
        "        # increment train correct with correcly predicted labels per batch\n",
        "        trn_corr += batch_corr\n",
        "        \n",
        "        # set optimizer gradients to zero\n",
        "        sgd_opt.zero_grad()\n",
        "        # back propagate with loss\n",
        "        loss.backward()\n",
        "        # perform optimizer step\n",
        "        sgd_opt.step()\n",
        "\n",
        "    # set epoch's end time\n",
        "    e_end = time.time()\n",
        "        # print training metrics\n",
        "    print(f'Epoch {(i+1)} Batch {(b+1)*4}\\nAccuracy: {trn_corr.item()*100/(4*8*b):2.2f} %  Loss: {loss.item():2.4f}  Duration: {((e_end-e_start)/60):.2f} minutes') # 4 images per batch * 8 augmentations per image * batch length\n",
        "\n",
        "    # some metrics storage for visualization\n",
        "    train_b = b\n",
        "    train_losses.append(loss)\n",
        "    train_accs.append(trn_corr)\n",
        "\n",
        "    X, y = None, None\n",
        "\n",
        "    # validate using validation generator\n",
        "    # do not perform any gradient updates while validation\n",
        "    with torch.no_grad():\n",
        "        for b, (y, X) in enumerate(val_loader):\n",
        "            # set label as cuda if device is cuda\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # forward pass image\n",
        "            y_val = resnet_50(X.view(-1, 3, 512, 512))\n",
        "\n",
        "            # get argmax of predicted tensor, which is our label\n",
        "            predicted = torch.argmax(y_val, dim=1).data\n",
        "\n",
        "            # increment test correct with correcly predicted labels per batch\n",
        "            tst_corr += (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n",
        "\n",
        "    # get loss of validation set\n",
        "    loss = crossen_loss(y_val.float(), torch.argmax(y.view(32, 4), dim=1).long())\n",
        "    # print validation metrics\n",
        "    print(f'Validation Accuracy {tst_corr.item()*100/(4*8*b):2.2f} Validation Loss: {loss.item():2.4f}\\n')\n",
        "\n",
        "    # if current validation loss is less than previous iteration's validatin loss create and save a checkpoint\n",
        "    is_best = loss < best_loss\n",
        "    best_loss = min(loss, best_loss)\n",
        "    save_model({\n",
        "            'epoch': i + 1,\n",
        "            'state_dict': resnet_50.state_dict(),\n",
        "            'best_prec1': best_loss,\n",
        "        }, is_best)\n",
        "\n",
        "    # some metrics storage for visualization\n",
        "    test_b  = b\n",
        "    test_losses.append(loss)\n",
        "    test_accs.append(tst_corr)\n",
        "\n",
        "# set total training's end time\n",
        "end_time = time.time() - start_time    \n",
        "\n",
        "# print training summary\n",
        "print(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\n",
        "print(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\n",
        "print(\"GPU memory cached : {} kb\".format(torch.cuda.memory_cached()))"
      ],
      "metadata": {
        "id": "LxogQaovxXCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "GshDuzzuxiQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(resnet_model.state_dict(), '/content/drive/My Drive/bt_resnet50_model.pt')"
      ],
      "metadata": {
        "id": "RRkOZjpoxr-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Validation accuracy: {test_correct[-1].item()*100/(test_b*8*4):.2f}%')"
      ],
      "metadata": {
        "id": "sa6GnWBtXAEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(test_losses, label='Validation loss')\n",
        "plt.title('Loss Metrics')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ey3CPbdZXG1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([t/171 for t in train_correct], label='Training accuracy')\n",
        "plt.plot([t/36 for t in test_correct], label='Validation accuracy')\n",
        "plt.title('Accuracy Metrics')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XD2JgQ3uXJ0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = None\n",
        "valid_gen = None\n",
        "train_set = None\n",
        "valid_set = None"
      ],
      "metadata": {
        "id": "Tub2ZApdXL9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set model to evaluation mode\n",
        "resnet_model.eval()\n",
        "\n",
        "# perform no gradient updates\n",
        "with torch.no_grad():\n",
        "    # soem metrics storage for visualization and analysis\n",
        "    correct = 0\n",
        "    test_loss = []\n",
        "    test_corr = []\n",
        "    labels = []\n",
        "    pred = []\n",
        "    # perform test set evaluation batch wise\n",
        "    for (y, X) in test_gen:\n",
        "        # set label to use CUDA if available\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # append original labels\n",
        "        labels.append(torch.argmax(y.view(10 * 8, 4), dim=1).data)\n",
        "\n",
        "        # perform forward pass\n",
        "        y_val = resnet_model(X.view(-1, 3, 512, 512))\n",
        "\n",
        "        # get argmax of predicted values, which is our label\n",
        "        predicted = torch.argmax(y_val, dim=1).data\n",
        "        # append predicted label\n",
        "        pred.append(predicted)\n",
        "\n",
        "        # calculate loss\n",
        "        loss = criterion(y_val.float(), torch.argmax(y.view(10 * 8, 4), dim=1).long())\n",
        "\n",
        "        # increment correct with correcly predicted labels per batch\n",
        "        correct += (predicted == torch.argmax(y.view(10 * 8, 4), dim=1)).sum()\n",
        "\n",
        "        # append correct samples labels and losses\n",
        "        test_corr.append(correct)\n",
        "        test_loss.append(loss)\n",
        "        \n",
        "print(f\"Test Loss: {test_loss[-1].item():.4f}\")"
      ],
      "metadata": {
        "id": "7nxhCJFIXO71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test accuracy: {test_corr[-1].item()*100/(460*8):.2f}%')"
      ],
      "metadata": {
        "id": "Rblzssn6XSYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.stack(labels)\n",
        "pred = torch.stack(pred)"
      ],
      "metadata": {
        "id": "0DK7MFpyXUlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = ['Meningioma', 'Glioma', 'Pitutary']"
      ],
      "metadata": {
        "id": "G2EuKik1XWgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = confusion_matrix(pred.view(-1).cpu(), labels.view(-1).cpu())\n",
        "df_cm = pd.DataFrame(arr, LABELS, LABELS)\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='viridis')\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Target\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "00eAx8BBXWn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Clasification Report\\n\\n{classification_report(pred.view(-1).cpu(), labels.view(-1).cpu())}\")"
      ],
      "metadata": {
        "id": "FMphviHdXcWL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}